{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Visualizer:\n",
    "    def __init__(self, show_step=10, image_size=30):\n",
    "        self.transform = transforms.Compose([transforms.Normalize(mean = [-2.118, -2.036, -1.804], # Equivalent to un-normalizing ImageNet (for correct visualization)\n",
    "                                                                    std = [4.367, 4.464, 4.444]),\n",
    "                                            transforms.ToPILImage(),\n",
    "                                            transforms.Scale(image_size)])\n",
    "\n",
    "        self.show_step = show_step\n",
    "        self.step = 0\n",
    "\n",
    "        self.figure, (self.lr_plot, self.hr_plot, self.fake_plot) = plt.subplots(1,3)\n",
    "        self.figure.show()\n",
    "\n",
    "        self.lr_image_ph = None\n",
    "        self.hr_image_ph = None\n",
    "        self.fake_hr_image_ph = None\n",
    "\n",
    "    def show(self, inputsG, inputsD_real, inputsD_fake):\n",
    "\n",
    "        self.step += 1\n",
    "        if self.step == self.show_step:\n",
    "            self.step = 0\n",
    "\n",
    "            i = random.randint(0, inputsG.size(0) -1)\n",
    "\n",
    "            lr_image = self.transform(inputsG[i])\n",
    "            hr_image = self.transform(inputsD_real[i])\n",
    "            fake_hr_image = self.transform(inputsD_fake[i])\n",
    "\n",
    "            if self.lr_image_ph is None:\n",
    "                self.lr_image_ph = self.lr_plot.imshow(lr_image)\n",
    "                self.hr_image_ph = self.hr_plot.imshow(hr_image)\n",
    "                self.fake_hr_image_ph = self.fake_plot.imshow(fake_hr_image)\n",
    "            else:\n",
    "                self.lr_image_ph.set_data(lr_image)\n",
    "                self.hr_image_ph.set_data(hr_image)\n",
    "                self.fake_hr_image_ph.set_data(fake_hr_image)\n",
    "\n",
    "            self.figure.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,channels):\n",
    "        super(ResidualBlock,self).__init__()\n",
    "        self.conv1=nn.Conv2d(channels,channels,kernel_size=3,padding=1)\n",
    "        self.bn1=nn.BatchNorm2d(channels)\n",
    "        self.prelu=nn.PReLU()\n",
    "        self.conv2=nn.Conv2d(channels,channels,kernel_size=3,padding=1)\n",
    "        self.bn2=nn.BatchNorm2d(channels)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        residual=self.conv1(x)\n",
    "        residual=self.bn1(residual)\n",
    "        residual=self.prelu(residual)\n",
    "        residual=self.conv2(residual)\n",
    "        residual=self.bn2(residual)\n",
    "        return residual+x\n",
    "        \n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self,in_channels,up_scale):\n",
    "        super(Upsample,self).__init__()\n",
    "        self.conv=nn.Conv2d(in_channels,in_channels*up_scale**2,kernel_size=3,padding=1)\n",
    "        self.pix_shuff=nn.PixelShuffle(up_scale)\n",
    "        self.prelu=nn.PReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.conv(x)\n",
    "        x=self.pix_shuff(x)\n",
    "        x=self.prelu(x)\n",
    "        return x\n",
    "\n",
    "        \n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        upsample_block_num=1\n",
    "        self.block1=nn.Sequential(\n",
    "        nn.Conv2d(3,64,kernel_size=9,padding=4),\n",
    "        nn.PReLU(),\n",
    "        )\n",
    "        self.block2 = ResidualBlock(64)\n",
    "        self.block3 = ResidualBlock(64)\n",
    "        self.block4 = ResidualBlock(64)\n",
    "        self.block5 = ResidualBlock(64)\n",
    "        self.block6 = ResidualBlock(64)\n",
    "        self.block7 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.PReLU())\n",
    "        \n",
    "        block8=[Upsample(64,2) for _ in range (upsample_block_num)]\n",
    "        block8.append(nn.Conv2d(64,3,kernel_size=9,padding=4))\n",
    "        self.block8=nn.Sequential(*block8)\n",
    "\n",
    "    def forward(self,x):\n",
    "        block1=self.block1(x)\n",
    "        block2=self.block2(block1)\n",
    "        block3=self.block3(block2)\n",
    "        block4=self.block4(block3)\n",
    "        block5=self.block5(block4)\n",
    "        block6=self.block6(block5)\n",
    "        block7=self.block7(block6)\n",
    "        block8=self.block8(block1+block7)\n",
    "    \n",
    "        return (F.tanh(block8)+1)/2\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.net=nn.Sequential(\n",
    "        nn.Conv2d(3,64,kernel_size=3,padding=1),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(64,64,kernel_size=3,stride=2,padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(64,128,kernel_size=3,padding=1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(128,128,kernel_size=3,stride=2,padding=1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.LeakyReLU(0.2),\n",
    "            \n",
    "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        \n",
    "        nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(512, 1024, kernel_size=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(1024, 1, kernel_size=1)\n",
    "            \n",
    "        )\n",
    "        \n",
    "        def forward(self,x):\n",
    "            batch_size=x.size(0)\n",
    "            return F.sigmoid(self.net(x).view(batch_size))\n",
    "            \n",
    "class Feature(nn.Module):\n",
    "    \n",
    "    def __init__(self,model,feature_layer=11):\n",
    "        super(Feature,self).__init__()\n",
    "        self.features=nn.Sequential(*list(model.features.children())[:feature_layer+1]) #for features\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.features(x)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infero/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n",
      "/home/infero/.local/lib/python3.6/site-packages/matplotlib/figure.py:457: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "3334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infero/.local/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/infero/.local/lib/python3.6/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/infero/.local/lib/python3.6/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/infero/.local/lib/python3.6/site-packages/ipykernel_launcher.py:72: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "gen=Generator()\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "transform = transforms.Compose([\n",
    "transforms.ToTensor()])\n",
    "disc=Discriminator()\n",
    "\n",
    "visualizer = Visualizer(image_size=64)\n",
    "normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                std = [0.229, 0.224, 0.225])\n",
    "\n",
    "scale = transforms.Compose([transforms.ToPILImage(),\n",
    "                            transforms.Scale(32),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                                std = [0.229, 0.224, 0.225])\n",
    "])\n",
    "feature_extractor=Feature(torchvision.models.vgg19(pretrained=True))\n",
    "\n",
    "content_criterion=nn.MSELoss()\n",
    "\n",
    "adv_criterion=nn.BCELoss()\n",
    "\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=15,\n",
    "shuffle=True)\n",
    "print(len(dataloader))\n",
    "\n",
    "bs=15\n",
    "ones_const = Variable(torch.ones(bs, 1))\n",
    "\n",
    "gen.cuda()\n",
    "disc.cuda()\n",
    "feature_extractor.cuda()\n",
    "content_criterion.cuda()\n",
    "adv_criterion.cuda()\n",
    "ones_const.cuda()\n",
    "\n",
    "optim_g=optim.Adam(gen.parameters(),lr=0.01)\n",
    "optim_d=optim.Adam(disc.parameters(),lr=0.01)\n",
    "\n",
    "\n",
    "low_res=torch.FloatTensor(bs,3,32,32)\n",
    "low_res=Variable(low_res.cuda())\n",
    "\n",
    "#pretraining the gen\n",
    "\n",
    "for epoch in range(2):\n",
    "    mean_gen_loss=0.0\n",
    "    \n",
    "    for i,data in enumerate(dataloader,0):\n",
    "        \n",
    "        high_res_real,labels=data\n",
    "        \n",
    "        #downsample into low_res\n",
    "        for j in range (bs):\n",
    "            low_res[j]=scale(high_res_real[j])\n",
    "            high_res_real[j]=normalize(high_res_real[j])\n",
    "        \n",
    "        high_res_real=high_res_real.cuda()\n",
    "        \n",
    "        high_res_fake=gen(low_res)\n",
    "        \n",
    "        gen.zero_grad()\n",
    "        high_res_fake=F.upsample(high_res_fake,size=(32,32),mode='bilinear')\n",
    "        gen_content_loss=content_criterion(high_res_fake,high_res_real)\n",
    "        mean_gen_loss+=gen_content_loss.data[0]\n",
    "        gen_content_loss.backward()\n",
    "        \n",
    "        optim_g.step()\n",
    "        \n",
    "        visualizer.show(low_res.cpu().data, high_res_real.cpu().data, high_res_fake.cpu().data)\n",
    "        \n",
    "#SRGAN training \n",
    "\n",
    "for epoch in range(opt.nEpochs):\n",
    "    mean_generator_content_loss = 0.0\n",
    "    mean_generator_adversarial_loss = 0.0\n",
    "    mean_generator_total_loss = 0.0\n",
    "    mean_discriminator_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # Generate data\n",
    "        high_res_real, _ = data\n",
    "\n",
    "        # Downsample images to low resolution\n",
    "        for j in range(opt.batchSize):\n",
    "            low_res[j] = scale(high_res_real[j])\n",
    "            high_res_real[j] = normalize(high_res_real[j])\n",
    "\n",
    "        # Generate real and fake inputs\n",
    "        \n",
    "        high_res_real = Variable(high_res_real.cuda())\n",
    "        high_res_fake = gen(Variable(low_res).cuda())\n",
    "        \n",
    "        target_real = Variable(torch.rand(opt.batchSize,1)*0.5 + 0.7).cuda()\n",
    "        target_fake = Variable(torch.rand(opt.batchSize,1)*0.3).cuda()\n",
    "\n",
    "        ######### Train discriminator #########\n",
    "        disc.zero_grad()\n",
    "\n",
    "        discriminator_loss = adv_criterion(disc(high_res_real), target_real) + \\\n",
    "                             adv_criterion(disc(Variable(high_res_fake.data)), target_fake)\n",
    "        mean_discriminator_loss += discriminator_loss.data[0]\n",
    "        \n",
    "        discriminator_loss.backward()\n",
    "        optim_discriminator.step()\n",
    "\n",
    "        ######### Train generator #########\n",
    "        generator.zero_grad()\n",
    "\n",
    "        real_features = Variable(feature_extractor(high_res_real).data)\n",
    "        fake_features = feature_extractor(high_res_fake)\n",
    "        high_res_fake=F.upsample(high_res_fake,size=(32,32),mode='bilinear')\n",
    "        \n",
    "        generator_content_loss = content_criterion(high_res_fake, high_res_real) + 0.006*content_criterion(fake_features, real_features)\n",
    "        mean_generator_content_loss += gen_content_loss.data[0]\n",
    "        generator_adversarial_loss = adv_criterion(discriminator(high_res_fake), ones_const)\n",
    "        mean_generator_adversarial_loss += generator_adversarial_loss.data[0]\n",
    "\n",
    "        generator_total_loss = generator_content_loss + 1e-3*generator_adversarial_loss\n",
    "        mean_generator_total_loss += generator_total_loss.data[0]\n",
    "        \n",
    "        generator_total_loss.backward()\n",
    "        optim_g.step()   \n",
    "        \n",
    "        \n",
    "        ######### Status and display #########\n",
    "        sys.stdout.write('\\r[%d/%d][%d/%d] Discriminator_Loss: %.4f Generator_Loss (Content/Advers/Total): %.4f/%.4f/%.4f' % (epoch, opt.nEpochs, i, len(dataloader),\n",
    "        discriminator_loss.data[0], generator_content_loss.data[0], generator_adversarial_loss.data[0], generator_total_loss.data[0]))\n",
    "        visualizer.show(low_res.cpu().data, high_res_real.cpu().data, high_res_fake.cpu().data)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
