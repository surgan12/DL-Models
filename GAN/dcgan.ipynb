{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (35) : CUDA driver version is insufficient for CUDA runtime version at /pytorch/aten/src/THC/THCGeneral.cpp:74",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6371d3d4a2bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_output_channel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (35) : CUDA driver version is insufficient for CUDA runtime version at /pytorch/aten/src/THC/THCGeneral.cpp:74"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "def my_weight_init(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        init.xavier_uniform(m.weight.data)\n",
    "        init.constant(m.bias.data, 0)\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, z_size, initial_feature_size=512, n_output_channel=1, alpha=0.2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.initial_feature_size = initial_feature_size\n",
    "\n",
    "        # make 3x3x512\n",
    "        n_first_layer_units = 3 * 3 * initial_feature_size\n",
    "        self.fc1 = torch.nn.Linear(z_size, n_first_layer_units, bias=True)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(initial_feature_size)\n",
    "\n",
    "        # make 7x7x256\n",
    "        self.deconv2 = torch.nn.ConvTranspose2d(initial_feature_size, initial_feature_size//2, kernel_size=3, stride=2, padding=0, bias=True, output_padding=0)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(initial_feature_size//2)\n",
    "\n",
    "        # make 14x14x128\n",
    "        self.deconv3 = torch.nn.ConvTranspose2d(initial_feature_size//2, initial_feature_size//4, kernel_size=5, stride=2, padding=2, bias=True, output_padding=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(initial_feature_size//4)\n",
    "\n",
    "        # make 28x28x1\n",
    "        self.deconv4 = torch.nn.ConvTranspose2d(initial_feature_size//4, n_output_channel, kernel_size=5, stride=2, padding=2, bias=True, output_padding=1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            my_weight_init(m)\n",
    "            \n",
    "\n",
    "    def forward(self, input):\n",
    "        l1 = self.fc1(input)\n",
    "        l1 = l1.view(-1, self.initial_feature_size, 3, 3) # reshape\n",
    "        l1 = torch.nn.functional.leaky_relu(self.bn1(l1), negative_slope=self.alpha)\n",
    "\n",
    "        l2 = torch.nn.functional.leaky_relu(self.bn2(self.deconv2(l1)), negative_slope=self.alpha)\n",
    "        l3 = torch.nn.functional.leaky_relu(self.bn3(self.deconv3(l2)), negative_slope=self.alpha)\n",
    "        l4 = self.deconv4(l3)\n",
    "        out = torch.nn.functional.tanh(l4)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, x_size, initial_feature_size=64, n_output=1, alpha=0.2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.initial_feature_size = initial_feature_size\n",
    "\n",
    "        # input is 28x28x1\n",
    "\n",
    "        # make 14x14x64\n",
    "        self.conv1 = torch.nn.Conv2d(x_size, initial_feature_size, kernel_size=5, stride=2, padding=2, bias=True)\n",
    "\n",
    "        # make 7x7x128\n",
    "        self.conv2 = torch.nn.Conv2d(initial_feature_size, initial_feature_size*2, kernel_size=5, stride=2, padding=2, bias=True)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(initial_feature_size*2)\n",
    "\n",
    "        # make 4x4x256\n",
    "        self.conv3 = torch.nn.Conv2d(initial_feature_size*2, initial_feature_size*4, kernel_size=5, stride=2, padding=2, bias=True)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(initial_feature_size*4)\n",
    "\n",
    "        self.fc4 = torch.nn.Linear(4 * 4 * initial_feature_size*4, n_output, bias=True)\n",
    "\n",
    "        for m in self.modules():\n",
    "            my_weight_init(m)\n",
    "\n",
    "    def forward(self, input):\n",
    "        l1 = torch.nn.functional.leaky_relu(self.conv1(input), negative_slope=self.alpha)\n",
    "        l2 = torch.nn.functional.leaky_relu(self.bn2(self.conv2(l1)), negative_slope=self.alpha)\n",
    "        l3 = torch.nn.functional.leaky_relu(self.bn3(self.conv3(l2)), negative_slope=self.alpha)\n",
    "        flattened = l3.view(-1, 4 * 4 * self.initial_feature_size*4) # reshape\n",
    "        l4 = self.fc4(flattened)\n",
    "        out = torch.nn.functional.sigmoid(l4)\n",
    "\n",
    "        return out\n",
    "\n",
    "# image save function\n",
    "def save_generator_output(G, fixed_z, img_str, title):\n",
    "    n_images = fixed_z.size()[0]\n",
    "    n_rows = np.sqrt(n_images).astype(np.int32)\n",
    "    n_cols = np.sqrt(n_images).astype(np.int32)\n",
    "    \n",
    "    z_ = Variable(fixed_z.cuda())\n",
    "    samples = G(z_)\n",
    "    samples = samples.cpu().data.numpy()\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(5,5), sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), samples):\n",
    "        ax.axis('off')\n",
    "        ax.set_adjustable('box-forced')\n",
    "        ax.imshow(img.reshape((28,28)), cmap='Greys_r', aspect='equal')\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.suptitle(title)\n",
    "    plt.savefig(img_str)\n",
    "    plt.close(fig)\n",
    "\n",
    "'''\n",
    "Parameters\n",
    "'''\n",
    "image_width = 28\n",
    "image_height = 28\n",
    "image_channels = 1\n",
    "x_size = image_channels\n",
    "z_size = 100\n",
    "# n_hidden = 128\n",
    "# n_classes = 10\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "alpha = 0.2\n",
    "beta1 = 0.5\n",
    "print_every = 50\n",
    "\n",
    "# build network\n",
    "G = Generator(z_size, n_output_channel=image_channels, alpha=alpha)\n",
    "D = Discriminator(x_size, n_output=1, alpha=alpha)\n",
    "G.cuda()\n",
    "D.cuda()\n",
    "\n",
    "# optimizer\n",
    "BCE_loss = torch.nn.BCELoss()\n",
    "G_opt = torch.optim.Adam( G.parameters(), lr=learning_rate, betas=[beta1, 0.999] )\n",
    "D_opt = torch.optim.Adam( D.parameters(), lr=learning_rate, betas=[beta1, 0.999] )\n",
    "\n",
    "assets_dir = './assets/'\n",
    "if not os.path.isdir(assets_dir):\n",
    "    os.mkdir(assets_dir)\n",
    "\n",
    "'''\n",
    "Start training\n",
    "'''\n",
    "step = 0\n",
    "samples = []\n",
    "losses = []\n",
    "fixed_z = torch.Tensor(25, z_size).uniform_(-1, 1)\n",
    "start_time = time.time()\n",
    "for e in range(epochs):\n",
    "    for x_, _ in train_loader:\n",
    "        step += 1\n",
    "        '''\n",
    "        Train in Discriminator\n",
    "        '''\n",
    "        # reshape input image\n",
    "        #x_ = x_.view(-1, image_channels, image_width, image_height)\n",
    "        # print(x_.size())\n",
    "        current_batch_size = x_.size()[0]\n",
    "\n",
    "        # create labels for loss computation\n",
    "        y_real_ = torch.ones(current_batch_size)\n",
    "        y_fake_ = torch.zeros(current_batch_size)\n",
    "\n",
    "        # make it cuda Tensor\n",
    "        x_, y_real_, y_fake_ = Variable(x_.cuda()), Variable(y_real_.cuda()), Variable(y_fake_.cuda())\n",
    "\n",
    "        # run real input on Discriminator\n",
    "        D_result_real = D(x_)\n",
    "        D_loss_real = BCE_loss(D_result_real, y_real_)\n",
    "\n",
    "        # run Generator input on Discriminator\n",
    "        z1_ = torch.Tensor(current_batch_size, z_size).uniform_(-1, 1)\n",
    "        z1_ = Variable(z1_.cuda())\n",
    "        x_fake = G(z1_)\n",
    "        D_result_fake = D(x_fake)\n",
    "        D_loss_fake = BCE_loss(D_result_fake, y_fake_)\n",
    "\n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "        # optimize Discriminator\n",
    "        D.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_opt.step()\n",
    "        \n",
    "        '''\n",
    "        Train in Generator\n",
    "        '''\n",
    "        z2_ = torch.Tensor(current_batch_size, z_size).uniform_(-1, 1)\n",
    "        y_ = torch.ones(current_batch_size)\n",
    "        z2_, y_ = Variable(z2_.cuda()), Variable(y_.cuda())\n",
    "        G_result = G(z2_)\n",
    "        D_result_fake2 = D(G_result)\n",
    "        G_loss = BCE_loss(D_result_fake2, y_)\n",
    "\n",
    "        G.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_opt.step()\n",
    "\n",
    "        if step % print_every == 0:\n",
    "            losses.append((D_loss.data[0], G_loss.data[0]))\n",
    "\n",
    "            print(\"Epoch {}/{}...\".format(e+1, epochs),\n",
    "                \"Discriminator Loss: {:.4f}...\".format(D_loss.data[0]),\n",
    "                \"Generator Loss: {:.4f}\".format(G_loss.data[0])) \n",
    "    # Sample from generator as we're training for viewing afterwards\n",
    "    image_fn = './assets/epoch_{:d}_pytorch.png'.format(e)\n",
    "    image_title = 'epoch {:d}'.format(e)\n",
    "    save_generator_output(G, fixed_z, image_fn, image_title)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print('Elapsed time: ', total_time)\n",
    "# 30 epochs: 751.90\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses.T[0], label='Discriminator', alpha=0.5)\n",
    "plt.plot(losses.T[1], label='Generator', alpha=0.5)\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()\n",
    "plt.savefig('./assets/losses_pytorch.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
