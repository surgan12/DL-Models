{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Front_End(nn.Module):\n",
    "    '''front end of disc and q remains same only at the end that probability changes'''\n",
    "    def __init__(self):\n",
    "        super(Front_End,self).__init__()\n",
    "        self.main=nn.Sequential(nn.Conv2d(1,64,4,2,1),\n",
    "        nn.LeakyReLU(0.1,inplace=True),\n",
    "        nn.Conv2d(64,128,4,2,1,bias=False),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.LeakyReLU(0.1,inplace=True),\n",
    "        nn.Conv2d(128,1024,7,bias=False),\n",
    "        nn.BatchNorm2d(1024),\n",
    "        nn.LeakyReLU(0.1,inplace=True),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        output=self.main(x)\n",
    "        return output\n",
    "\n",
    "class Disc(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Disc,self).__init__()\n",
    "        self.main=nn.Sequential(\n",
    "        nn.Conv2d(1024,1,1),\n",
    "        nn.Sigmoid(),)\n",
    "    def forward(self,x):\n",
    "        output=self.main(x)\n",
    "        output=output.view(-1,1)\n",
    "        return output\n",
    "\n",
    "class Qr(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Qr,self).__init__()\n",
    "        self.conv=nn.Conv2d(1024,128,1)\n",
    "        self.bn=nn.BatchNorm2d(128)\n",
    "        self.lRELU = nn.LeakyReLU(0.1,inplace=True)\n",
    "        self.conv_disc=nn.Conv2d(128,10,1)\n",
    "        self.conv_mu=nn.Conv2d(128,2,1)\n",
    "        self.conv_var=nn.Conv2d(128,2,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y=self.conv(x)\n",
    "        disc_logits=self.conv_disc(y).squeeze()\n",
    "        mu=self.conv_mu(y).squeeze()\n",
    "        var=self.conv_var(y).squeeze()\n",
    "        \n",
    "        return disc_logits,mu,var\n",
    "\n",
    "\n",
    "class Gen(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Gen,self).__init__()\n",
    "        \n",
    "        self.main=nn.Sequential(\n",
    "            nn.ConvTranspose2d(74,1024,1,1,bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(1024,128,7,1,bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128,64,4,2,1,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64,1,4,2,1,bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        output=self.main(x)\n",
    "        return output\n",
    "    \n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class log_gaussian:\n",
    "\n",
    "  def __call__(self, x, mu, var):\n",
    "\n",
    "    logli = -0.5*(var.mul(2*np.pi)+1e-6).log() - \\\n",
    "            (x-mu).pow(2).div(var.mul(2.0)+1e-6)\n",
    "    \n",
    "    return logli.sum(1).mean().mul(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=100\n",
    "idx = np.random.randint(10,size=100)\n",
    "c = np.zeros((bs, 10))\n",
    "c[range(bs),idx] = 1.0\n",
    "\n",
    "dis_c=torch.Tensor(c).cuda()\n",
    "con_c=torch.Tensor(100,2).uniform_(-1.0,1.0).cuda()\n",
    "noise=torch.Tensor(100,62).uniform_(-1.0,1.0).cuda()\n",
    "z = torch.cat([noise, dis_c, con_c], 1).view(-1, 74, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "batch_size=bs\n",
    "# data_loader normalize [0, 1] ==> [-1, 1]\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('../Data_sets/MNIST_data', train=True, download=True, transform=transform),\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterionD=nn.BCELoss().cuda()\n",
    "criterionQ_dis=nn.CrossEntropyLoss().cuda()\n",
    "criterionQ_con=log_gaussian()\n",
    "FE=Front_End()\n",
    "G=Gen()\n",
    "D=Disc()\n",
    "Q=Qr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surgan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch/Iter:0/0, Dloss: 1.390260100364685, Gloss: 2.876046657562256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-7d2d6f171c72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss_real\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterionD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_real\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreal_lab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m74\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mfake_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mfe_out2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimD = optim.Adam([{'params':FE.parameters()}, {'params':D.parameters()}], lr=0.0002, betas=(0.5, 0.99))\n",
    "optimG = optim.Adam([{'params':G.parameters()}, {'params':Q.parameters()}], lr=0.001, betas=(0.5, 0.99))\n",
    "\n",
    "x = np.linspace(-1, 1, 10).reshape(1, -1)\n",
    "x = np.repeat(x, 10, 0).reshape(-1, 1)\n",
    "\n",
    "c1 = np.hstack([x, np.zeros_like(x)])\n",
    "c2 = np.hstack([np.zeros_like(x), x])\n",
    "\n",
    "idx = np.arange(10).repeat(10)\n",
    "one_hot = np.zeros((100, 10))\n",
    "one_hot[range(100), idx] = 1\n",
    "fix_noise = torch.Tensor(100, 62).uniform_(-1, 1).cuda()\n",
    "\n",
    "for epoch in range(10):\n",
    "    for num_iters,data in enumerate(train_loader,0):\n",
    "        real_x,labels=data\n",
    "        idx = np.random.randint(10,size=100)\n",
    "        c = np.zeros((bs, 10))\n",
    "        c[range(bs),idx] = 1.0\n",
    "\n",
    "        dis_c=torch.Tensor(c).cuda()\n",
    "        con_c=torch.Tensor(100,2).uniform_(-1.0,1.0).cuda()\n",
    "        noise=torch.Tensor(100,62).uniform_(-1.0,1.0).cuda()\n",
    "        fe_out1=FE(real_x)\n",
    "        probs_real=D(fe_out1)\n",
    "        real_lab=torch.ones(bs).cuda()\n",
    "        loss_real=criterionD(probs_real,real_lab)\n",
    "        loss_real.backward()\n",
    "        z = torch.cat([noise, dis_c, con_c], 1).view(-1, 74, 1, 1)\n",
    "        fake_x=G(z)\n",
    "        fe_out2=FE(fake_x.detach())\n",
    "        probs_fake=D(fe_out2)\n",
    "        fake_lab=torch.zeros(bs).cuda()\n",
    "        loss_fake=criterionD(probs_fake,fake_lab)                                   \n",
    "        loss_fake.backward()\n",
    "        D_loss=loss_real+loss_fake\n",
    "        optimD.step()\n",
    "        \n",
    "        #G & Q part\n",
    "        optimG.zero_grad()\n",
    "        fe_out=FE(fake_x)\n",
    "        probs_fake=D(fe_out)\n",
    "        label=torch.zeros(100).cuda()\n",
    "        class_ = torch.LongTensor(idx).cuda()\n",
    "        recon_loss=criterionD(probs_fake,label)\n",
    "        q_logits , q_mu, q_var=Q(fe_out)\n",
    "        dis_loss = criterionQ_dis(q_logits,class_)\n",
    "        con_loss = criterionQ_con(con_c, q_mu, q_var)*0.1\n",
    "        G_loss= recon_loss + dis_loss + con_loss\n",
    "        G_loss.backward()\n",
    "        optimG.step()\n",
    "        if num_iters % 100 == 0:\n",
    "\n",
    "          print('Epoch/Iter:{0}/{1}, Dloss: {2}, Gloss: {3}'.format(\n",
    "            epoch, num_iters, D_loss.data.cpu().numpy(),\n",
    "            G_loss.data.cpu().numpy())\n",
    "          )\n",
    "          f=torch.from_numpy(c1)\n",
    "          f=f.type(torch.FloatTensor).cuda()\n",
    "          tr=torch.FloatTensor(one_hot)\n",
    "          tr=tr.type(torch.FloatTensor).cuda()\n",
    "          z = torch.cat([noise, tr, f], 1).view(-1, 74, 1, 1)\n",
    "          x_save = G(z)\n",
    "          save_image(x_save.data, './tmp/c1.png', nrow=10)\n",
    "\n",
    "          f2=torch.from_numpy(c1)\n",
    "          f2=f2.type(torch.FloatTensor).cuda()\n",
    "          z = torch.cat([fix_noise, tr, f2], 1).view(-1, 74, 1, 1)\n",
    "          x_save = G(z)\n",
    "          save_image(x_save.data, './tmp/c2.png', nrow=10)\n",
    "        \n",
    "        \n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
