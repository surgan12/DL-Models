{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def my_weight_init(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        init.xavier_uniform(m.weight.data)\n",
    "        init.constant(m.bias.data, 0)\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, z_size, initial_feature_size=512, n_output_channel=1, alpha=0.2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.initial_feature_size = initial_feature_size\n",
    "\n",
    "        # make 3x3x512\n",
    "        n_first_layer_units = 3 * 3 * initial_feature_size\n",
    "        self.fc1 = torch.nn.Linear(z_size, n_first_layer_units, bias=True)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(initial_feature_size)\n",
    "\n",
    "        # make 7x7x256\n",
    "        self.deconv2 = torch.nn.ConvTranspose2d(initial_feature_size, initial_feature_size//2, kernel_size=3, stride=2, padding=0, bias=True, output_padding=0)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(initial_feature_size//2)\n",
    "\n",
    "        # make 14x14x128\n",
    "        self.deconv3 = torch.nn.ConvTranspose2d(initial_feature_size//2, initial_feature_size//4, kernel_size=5, stride=2, padding=2, bias=True, output_padding=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(initial_feature_size//4)\n",
    "\n",
    "        # make 28x28x1\n",
    "        self.deconv4 = torch.nn.ConvTranspose2d(initial_feature_size//4, n_output_channel, kernel_size=5, stride=2, padding=2, bias=True, output_padding=1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            my_weight_init(m)\n",
    "            \n",
    "\n",
    "    def forward(self, input):\n",
    "        l1 = self.fc1(input)\n",
    "        l1 = l1.view(-1, self.initial_feature_size, 3, 3) # reshape\n",
    "        l1 = torch.nn.functional.leaky_relu(self.bn1(l1), negative_slope=self.alpha)\n",
    "\n",
    "        l2 = torch.nn.functional.leaky_relu(self.bn2(self.deconv2(l1)), negative_slope=self.alpha)\n",
    "        l3 = torch.nn.functional.leaky_relu(self.bn3(self.deconv3(l2)), negative_slope=self.alpha)\n",
    "        l4 = self.deconv4(l3)\n",
    "        out = torch.nn.functional.tanh(l4)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, x_size, initial_feature_size=64, n_output=1, alpha=0.2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.initial_feature_size = initial_feature_size\n",
    "\n",
    "        # input is 28x28x1\n",
    "\n",
    "        # make 14x14x64\n",
    "        self.conv1 = torch.nn.Conv2d(x_size, initial_feature_size, kernel_size=5, stride=2, padding=2, bias=True)\n",
    "\n",
    "        # make 7x7x128\n",
    "        self.conv2 = torch.nn.Conv2d(initial_feature_size, initial_feature_size*2, kernel_size=5, stride=2, padding=2, bias=True)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(initial_feature_size*2)\n",
    "\n",
    "        # make 4x4x256\n",
    "        self.conv3 = torch.nn.Conv2d(initial_feature_size*2, initial_feature_size*4, kernel_size=5, stride=2, padding=2, bias=True)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(initial_feature_size*4)\n",
    "\n",
    "        self.fc4 = torch.nn.Linear(4 * 4 * initial_feature_size*4, n_output, bias=True)\n",
    "\n",
    "        for m in self.modules():\n",
    "            my_weight_init(m)\n",
    "\n",
    "    def forward(self, input,matching=True):\n",
    "        l1 = torch.nn.functional.leaky_relu(self.conv1(input), negative_slope=self.alpha)\n",
    "        l2 = torch.nn.functional.leaky_relu(self.bn2(self.conv2(l1)), negative_slope=self.alpha)\n",
    "        l3 = torch.nn.functional.leaky_relu(self.bn3(self.conv3(l2)), negative_slope=self.alpha)\n",
    "        flattened = l3.view(-1, 4 * 4 * self.initial_feature_size*4) # reshape\n",
    "        l4 = self.fc4(flattened)\n",
    "        out = torch.nn.functional.sigmoid(l4)\n",
    "        \n",
    "        if matching==False:\n",
    "            return out\n",
    "        else:\n",
    "            return flattened,out \n",
    "   \n",
    "\n",
    "# image save function\n",
    "def save_generator_output(G, fixed_z, img_str, title):\n",
    "    n_images = fixed_z.size()[0]\n",
    "    n_rows = np.sqrt(n_images).astype(np.int32)\n",
    "    n_cols = np.sqrt(n_images).astype(np.int32)\n",
    "    \n",
    "    z_ = Variable(fixed_z.cuda())\n",
    "    samples = G(z_)\n",
    "    samples = samples.cpu().data.numpy()\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(5,5), sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), samples):\n",
    "        ax.axis('off')\n",
    "        ax.set_adjustable('box-forced')\n",
    "        ax.imshow(img.reshape((28,28)), cmap='Greys_r', aspect='equal')\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.suptitle(title)\n",
    "    plt.savefig(img_str)\n",
    "    plt.close(fig)\n",
    "\n",
    "'''\n",
    "Parameters\n",
    "'''\n",
    "image_width = 28\n",
    "image_height = 28\n",
    "image_channels = 1\n",
    "x_size = image_channels\n",
    "z_size = 100\n",
    "# n_hidden = 128\n",
    "# n_classes = 10\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "alpha = 0.2\n",
    "beta1 = 0.5\n",
    "print_every = 50\n",
    "\n",
    "# build network\n",
    "G = Generator(z_size, n_output_channel=image_channels, alpha=alpha)\n",
    "D = Discriminator(x_size, n_output=1, alpha=alpha)\n",
    "G.cuda()\n",
    "D.cuda()\n",
    "\n",
    "# optimizer\n",
    "criterion_D = torch.nn.MSELoss()\n",
    "criterionG = nn.MSELoss()\n",
    "G_opt = torch.optim.Adam( G.parameters(), lr=learning_rate, betas=[beta1, 0.999] )\n",
    "D_opt = torch.optim.Adam( D.parameters(), lr=learning_rate, betas=[beta1, 0.999] )\n",
    "\n",
    "assets_dir = './assets/'\n",
    "if not os.path.isdir(assets_dir):\n",
    "    os.mkdir(assets_dir)\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
    "realimages = torchvision.datasets.MNIST(root='./data', train=True,download=True, transform=transform)\n",
    "train_loader= torch.utils.data.DataLoader(realimages, batch_size=100,shuffle=True, num_workers=2)\n",
    "    \n",
    "'''\n",
    "Start training\n",
    "'''\n",
    "step = 0\n",
    "samples = []\n",
    "losses = []\n",
    "fixed_z = torch.Tensor(25, z_size).uniform_(-1, 1)\n",
    "start_time = time.time()\n",
    "for e in range(epochs):\n",
    "    for x_, _ in train_loader:\n",
    "        step += 1\n",
    "        '''\n",
    "        Train in Discriminator\n",
    "        '''\n",
    "        # reshape input image\n",
    "        #x_ = x_.view(-1, image_channels, image_width, image_height)\n",
    "        # print(x_.size())\n",
    "        current_batch_size = x_.size()[0]\n",
    "\n",
    "        # create labels for loss computation\n",
    "        y_real_ = torch.ones(current_batch_size,1)\n",
    "        y_fake_ = torch.zeros(current_batch_size,1)\n",
    "\n",
    "        # make it cuda Tensor\n",
    "        x_, y_real_, y_fake_ = Variable(x_.cuda()), Variable(y_real_.cuda()), Variable(y_fake_.cuda())\n",
    "\n",
    "        # run real input on Discriminator\n",
    "        _,D_result_real = D(x_)\n",
    "\n",
    "        D_loss_real = criterion_D(D_result_real, y_real_)\n",
    "\n",
    "        # run Generator input on Discriminator\n",
    "        z1_ = torch.Tensor(current_batch_size, z_size).uniform_(-1, 1)\n",
    "        z1_ = Variable(z1_.cuda())\n",
    "        x_fake = G(z1_)\n",
    "        _,D_result_fake = D(x_fake)\n",
    "        \n",
    "        D_loss_fake = criterion_D(D_result_fake, y_fake_)\n",
    "        \n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "        # optimize Discriminator\n",
    "        D.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_opt.step()\n",
    "        \n",
    "        '''\n",
    "        Train in Generator\n",
    "        '''\n",
    "        z2_ = torch.Tensor(current_batch_size, z_size).uniform_(-1, 1)\n",
    "        y_ = torch.ones(current_batch_size)\n",
    "        z2_, y_ = Variable(z2_.cuda()), Variable(y_.cuda())\n",
    "        G_result = G(z2_)\n",
    "        \n",
    "        mom_gen, output_fake = D(G_result, matching=True)\n",
    "        mom_unlabel, _ = D(x_.detach(), matching=True)\n",
    "        mom_gen = torch.mean(mom_gen, dim = 0)\n",
    "        mom_unlabel = torch.mean(mom_unlabel, dim = 0)\n",
    "        G_loss = criterionG(mom_gen,mom_unlabel)\n",
    "        #loss_adv = -torch.mean(F.softplus(log_sum_exp(output_fake)))\n",
    "        \n",
    "        \n",
    "        G.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_opt.step()\n",
    "\n",
    "        if step % print_every == 0:\n",
    "            losses.append((D_loss.data[0], G_loss.data[0]))\n",
    "\n",
    "            print(\"Epoch {}/{}...\".format(e+1, epochs),\n",
    "                \"Discriminator Loss: {:.4f}...\".format(D_loss.data[0]),\n",
    "                \"Generator Loss: {:.4f}\".format(G_loss.data[0])) \n",
    "    # Sample from generator as we're training for viewing afterwards\n",
    "    image_fn = './assets/epoch_{:d}_pytorch.png'.format(e)\n",
    "    image_title = 'epoch {:d}'.format(e)\n",
    "    save_generator_output(G, fixed_z, image_fn, image_title)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print('Elapsed time: ', total_time)\n",
    "# 30 epochs: 751.90\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses.T[0], label='Discriminator', alpha=0.5)\n",
    "plt.plot(losses.T[1], label='Generator', alpha=0.5)\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()\n",
    "plt.savefig('./assets/losses_pytorch.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
